<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>knncolle: Collection of KNN algorithms</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">knncolle
   </div>
   <div id="projectbrief">Collection of KNN methods in C++</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Collection of KNN algorithms </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md__2github_2workspace_2README"></a> <img src="https://github.com/knncolle/knncolle/actions/workflows/run-tests.yaml/badge.svg" alt="Unit tests" style="pointer-events: none;" class="inline"/> <img src="https://github.com/knncolle/knncolle/actions/workflows/doxygenate.yaml/badge.svg" alt="Documentation" style="pointer-events: none;" class="inline"/> <a href="https://codecov.io/gh/knncolle/knncolle"><img src="https://codecov.io/gh/knncolle/knncolle/branch/master/graph/badge.svg" alt="Codecov" style="pointer-events: none;" class="inline"/></a></p>
<h1>Overview</h1>
<p><b>knncolle</b> is a header-only C++ library that collects a variety of different k-nearest neighbor algorithms under a consistent interface. The aim is to enable downstream libraries to easily switch between different methods with a single runtime flag, or by just swapping out the relevant constructors at compile time.</p>
<p>The core library supports the following methods:</p>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/22247818/">K-means with k-nearest neighbors</a>, an exact search that uses k-means clustering to index points.</li>
<li><a href="http://stevehanov.ca/blog/?id=130">Vantage point tree</a>, an exact search that uses the tree of the same name.</li>
<li>Brute force search, mostly implemented for testing.</li>
</ul>
<p>This framework is extended by various add-on libraries to more algorithms:</p>
<ul>
<li><a href="https://github.com/knncolle/knncolle_annoy"><b>knncolle_annoy</b></a> supports <a href="https://github.com/spotify/annoy/">Annoy</a>, an approximate search based on random projections.</li>
<li><a href="https://github.com/knncolle/knncolle_hnsw"><b>knncolle_hnsw</b></a> supports <a href="https://github.com/nmslib/hnswlib/">HNSW</a>, an approximate search based on hierarchical graphs.</li>
</ul>
<p>Most of the code in this library is derived from the <a href="https://bioconductor.org/packages/release/bioc/html/BiocNeighbors.html"><b>BiocNeighbors</b> R package</a>.</p>
<h1>Quick start</h1>
<p>Given a matrix with dimensions in the rows and observations in the columns, we can do:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="knncolle_8hpp.html">knncolle/knncolle.hpp</a>&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Wrap our data in a light SimpleMatrix.</span></div>
<div class="line"><a class="code hl_class" href="classknncolle_1_1SimpleMatrix.html">knncolle::SimpleMatrix&lt;int, int, double&gt;</a> mat(ndim, nobs, matrix.data());</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Build a VP-tree index. </span></div>
<div class="line"><a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder&lt;&gt;</a> vp_builder;</div>
<div class="line"><span class="keyword">auto</span> vp_index = vp_builder.<a class="code hl_function" href="classknncolle_1_1Builder.html#afeda432debae999f988f32f147055251">build_unique</a>(mat);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Find 10 nearest neighbors of every observation.</span></div>
<div class="line"><span class="keyword">auto</span> results = <a class="code hl_function" href="namespaceknncolle.html#a22e035b2d5eb293fd828a67e61f3213d">knncolle::find_nearest_neighbors</a>(*vp_index, 10); </div>
<div class="line"> </div>
<div class="line">results[0].first; <span class="comment">// indices of neighbors of the first observation</span></div>
<div class="line">results[0].second; <span class="comment">// distances to neighbors of the first observation</span></div>
<div class="ttc" id="aclassknncolle_1_1Builder_html_afeda432debae999f988f32f147055251"><div class="ttname"><a href="classknncolle_1_1Builder.html#afeda432debae999f988f32f147055251">knncolle::Builder::build_unique</a></div><div class="ttdeci">std::unique_ptr&lt; Prebuilt&lt; typename Matrix_::dimension_type, typename Matrix_::index_type, Float_ &gt; &gt; build_unique(const Matrix_ &amp;data) const</div><div class="ttdef"><b>Definition</b> Builder.hpp:50</div></div>
<div class="ttc" id="aclassknncolle_1_1SimpleMatrix_html"><div class="ttname"><a href="classknncolle_1_1SimpleMatrix.html">knncolle::SimpleMatrix</a></div><div class="ttdoc">Simple wrapper for an in-memory matrix.</div><div class="ttdef"><b>Definition</b> MockMatrix.hpp:116</div></div>
<div class="ttc" id="aclassknncolle_1_1VptreeBuilder_html"><div class="ttname"><a href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder</a></div><div class="ttdoc">Perform a nearest neighbor search based on a vantage point (VP) tree.</div><div class="ttdef"><b>Definition</b> Vptree.hpp:406</div></div>
<div class="ttc" id="aknncolle_8hpp_html"><div class="ttname"><a href="knncolle_8hpp.html">knncolle.hpp</a></div><div class="ttdoc">Umbrella header for all algorithms.</div></div>
<div class="ttc" id="anamespaceknncolle_html_a22e035b2d5eb293fd828a67e61f3213d"><div class="ttname"><a href="namespaceknncolle.html#a22e035b2d5eb293fd828a67e61f3213d">knncolle::find_nearest_neighbors</a></div><div class="ttdeci">NeighborList&lt; Index_, Float_ &gt; find_nearest_neighbors(const Prebuilt&lt; Dim_, Index_, Float_ &gt; &amp;index, int k, int num_threads=1)</div><div class="ttdef"><b>Definition</b> find_nearest_neighbors.hpp:51</div></div>
</div><!-- fragment --><p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for more details.</p>
<h1>Searching in more detail</h1>
<p>We can perform the search manually by constructing a <code>Searcher</code> instance and looping over the elements of interest. Continuing with the same variables defined in the previous section, we could replace the <code>find_nearest_neighbors()</code> call with:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> searcher = vp_index-&gt;initialize();</div>
<div class="line">std::vector&lt;int&gt; indices;</div>
<div class="line">std::vector&lt;double&gt; distances;</div>
<div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> o = 0; o &lt; nobs; ++o) {</div>
<div class="line">    searcher-&gt;search(o, 10, &amp;indices, &amp;distances);</div>
<div class="line">    <span class="comment">// Do something with the search results for &#39;o&#39;.</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>Similarly, we can query the prebuilt index for the neighbors of an arbitrary vector. The code below searches for the nearest 5 neighbors to a query vector at the origin:</p>
<div class="fragment"><div class="line">std::vector&lt;double&gt; query(ndim);</div>
<div class="line">searcher-&gt;search(query.data(), 5, &amp;indices, &amp;distances);</div>
</div><!-- fragment --><p>To parallelize the loop, we just need to construct a separate <code>Searcher</code> (and the result vector) for each thread. This is already implemented in <code>find_nearest_neighbors()</code> but is also easy to do by hand, e.g., with OpenMP:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#pragma omp parallel num_threads(5)</span></div>
<div class="line">{</div>
<div class="line">    <span class="keyword">auto</span> searcher = vp_index-&gt;initialize();</div>
<div class="line">    std::vector&lt;int&gt; indices;</div>
<div class="line">    std::vector&lt;double&gt; distances;</div>
<div class="line"><span class="preprocessor">    #pragma omp for</span></div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> o = 0; o &lt; nobs; ++o) {</div>
<div class="line">        searcher-&gt;search(o, 10, &amp;indices, &amp;distances);</div>
<div class="line">        <span class="comment">// Do something with the search &#39;results&#39; for &#39;o&#39;.</span></div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>Either (or both) of <code>indices</code> and <code>distances</code> may be <code>NULL</code>, in which case the corresponding values are not reported. This allows implementations to skip the extraction of distances when only the identities of the neighbors are of interest.</p>
<div class="fragment"><div class="line">searcher-&gt;search(0, 5, &amp;indices, NULL);</div>
</div><!-- fragment --><h1>Finding all neighbors within range</h1>
<p>A related problem involves finding all neighbors within a certain distance of an observation. This can be achieved using the <code>Searcher::search_all()</code> method:</p>
<div class="fragment"><div class="line"><span class="keywordflow">if</span> (seacher-&gt;can_search_all()) {</div>
<div class="line">    <span class="comment">// Report all neighbors within a distance of 10 from the first point.</span></div>
<div class="line">    searcher-&gt;search_all(0, 10, &amp;indices, &amp;distances);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Report all neighbors within a distance of 0.5 from a query point.</span></div>
<div class="line">    searcher-&gt;search_all(query.data(), 0.5, &amp;indices, &amp;distances);</div>
<div class="line">}</div>
</div><!-- fragment --><p>This method is optional so developers of <code>Searcher</code> subclasses may choose to not implement it. Applications should check <code>Searcher::can_search_all()</code> before attempting a call, as shown above. Otherwise, the default method will raise an exception.</p>
<h1>Tuning index construction</h1>
<p>Some algorithms allow the user to modify the parameters of the search by passing options in the relevant <code>Builder</code> constructor. For example, the KMKNN method has several options for the k-means clustering step. We could, say, specify which initialization algorithm to use:</p>
<div class="fragment"><div class="line"><a class="code hl_struct" href="structknncolle_1_1KmknnOptions.html">knncolle::KmknnOptions&lt;&gt;</a> kk_opt;</div>
<div class="line">kk_opt.<a class="code hl_variable" href="structknncolle_1_1KmknnOptions.html#a01ab1d6e283fa8945723f33942e310c0">initialize_algorithm</a>.reset(</div>
<div class="line">    <span class="keyword">new</span> <a class="code hl_classRef" href="https://ltla.github.io/CppKmeans/classkmeans_1_1InitializeRandom.html">kmeans::InitializeRandom</a>&lt;<a class="code hl_classRef" href="https://ltla.github.io/CppKmeans/classkmeans_1_1SimpleMatrix.html">kmeans::SimpleMatrix&lt;double, int, int&gt;</a>, <span class="keywordtype">int</span>, <span class="keywordtype">double</span>&gt;</div>
<div class="line">);</div>
<div class="ttc" id="aclasskmeans_1_1InitializeRandom_html"><div class="ttname"><a href="https://ltla.github.io/CppKmeans/classkmeans_1_1InitializeRandom.html">kmeans::InitializeRandom</a></div></div>
<div class="ttc" id="aclasskmeans_1_1SimpleMatrix_html"><div class="ttname"><a href="https://ltla.github.io/CppKmeans/classkmeans_1_1SimpleMatrix.html">kmeans::SimpleMatrix</a></div></div>
<div class="ttc" id="astructknncolle_1_1KmknnOptions_html"><div class="ttname"><a href="structknncolle_1_1KmknnOptions.html">knncolle::KmknnOptions</a></div><div class="ttdoc">Options for KmknnBuilder and KmknnPrebuilt construction.</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:40</div></div>
<div class="ttc" id="astructknncolle_1_1KmknnOptions_html_a01ab1d6e283fa8945723f33942e310c0"><div class="ttname"><a href="structknncolle_1_1KmknnOptions.html#a01ab1d6e283fa8945723f33942e310c0">knncolle::KmknnOptions::initialize_algorithm</a></div><div class="ttdeci">std::shared_ptr&lt; kmeans::Initialize&lt; kmeans::SimpleMatrix&lt; Store_, Index_, Dim_ &gt;, Index_, Store_ &gt; &gt; initialize_algorithm</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:54</div></div>
</div><!-- fragment --><p>Or modify the behavior of the refinement algorithm:</p>
<div class="fragment"><div class="line"><a class="code hl_structRef" href="https://ltla.github.io/CppKmeans/structkmeans_1_1RefineLloydOptions.html">kmeans::RefineLloydOptions</a> ll_opt;</div>
<div class="line">ll_opt.<a class="code hl_variableRef" href="https://ltla.github.io/CppKmeans/structkmeans_1_1RefineLloydOptions.html#ac927615927b93f499bbabb24cfc3fb9a">max_iterations</a> = 20;</div>
<div class="line">ll_opt.<a class="code hl_variableRef" href="https://ltla.github.io/CppKmeans/structkmeans_1_1RefineLloydOptions.html#a016c4d237bde819fa8d5c5631c52360b">num_threads</a> = 5;</div>
<div class="line">kk_opt.<a class="code hl_variable" href="structknncolle_1_1KmknnOptions.html#adf03e5a3046a1da5cacff93d37975ff8">refine_algorithm</a>.reset(</div>
<div class="line">    <span class="keyword">new</span> <a class="code hl_classRef" href="https://ltla.github.io/CppKmeans/classkmeans_1_1RefineLloyd.html">kmeans::RefineLloyd</a>&lt;<a class="code hl_classRef" href="https://ltla.github.io/CppKmeans/classkmeans_1_1SimpleMatrix.html">kmeans::SimpleMatrix&lt;double, int, int&gt;</a>, <span class="keywordtype">int</span>, <span class="keywordtype">double</span>&gt;(ll_opt)</div>
<div class="line">);</div>
<div class="ttc" id="aclasskmeans_1_1RefineLloyd_html"><div class="ttname"><a href="https://ltla.github.io/CppKmeans/classkmeans_1_1RefineLloyd.html">kmeans::RefineLloyd</a></div></div>
<div class="ttc" id="astructkmeans_1_1RefineLloydOptions_html"><div class="ttname"><a href="https://ltla.github.io/CppKmeans/structkmeans_1_1RefineLloydOptions.html">kmeans::RefineLloydOptions</a></div></div>
<div class="ttc" id="astructkmeans_1_1RefineLloydOptions_html_a016c4d237bde819fa8d5c5631c52360b"><div class="ttname"><a href="https://ltla.github.io/CppKmeans/structkmeans_1_1RefineLloydOptions.html#a016c4d237bde819fa8d5c5631c52360b">kmeans::RefineLloydOptions::num_threads</a></div><div class="ttdeci">int num_threads</div></div>
<div class="ttc" id="astructkmeans_1_1RefineLloydOptions_html_ac927615927b93f499bbabb24cfc3fb9a"><div class="ttname"><a href="https://ltla.github.io/CppKmeans/structkmeans_1_1RefineLloydOptions.html#ac927615927b93f499bbabb24cfc3fb9a">kmeans::RefineLloydOptions::max_iterations</a></div><div class="ttdeci">int max_iterations</div></div>
<div class="ttc" id="astructknncolle_1_1KmknnOptions_html_adf03e5a3046a1da5cacff93d37975ff8"><div class="ttname"><a href="structknncolle_1_1KmknnOptions.html#adf03e5a3046a1da5cacff93d37975ff8">knncolle::KmknnOptions::refine_algorithm</a></div><div class="ttdeci">std::shared_ptr&lt; kmeans::Refine&lt; kmeans::SimpleMatrix&lt; Store_, Index_, Dim_ &gt;, Index_, Store_ &gt; &gt; refine_algorithm</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:60</div></div>
</div><!-- fragment --><p>After which, we construct our <code>KmknnBuilder</code>, build our <code>KmknnPrebuilt</code> index, and proceed with the nearest-neighbor search.</p>
<div class="fragment"><div class="line"><a class="code hl_class" href="classknncolle_1_1KmknnBuilder.html">knncolle::KmknnBuilder&lt;&gt;</a> kk_builder(kk_opt);</div>
<div class="line"><span class="keyword">auto</span> kk_prebuilt = kk_builder.build_unique(mat);</div>
<div class="line"><span class="keyword">auto</span> kk_results = <a class="code hl_function" href="namespaceknncolle.html#a22e035b2d5eb293fd828a67e61f3213d">knncolle::find_nearest_neighbors</a>(*kk_prebuilt, 10); </div>
<div class="ttc" id="aclassknncolle_1_1KmknnBuilder_html"><div class="ttname"><a href="classknncolle_1_1KmknnBuilder.html">knncolle::KmknnBuilder</a></div><div class="ttdoc">Perform a nearest neighbor search based on k-means clustering.</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:503</div></div>
</div><!-- fragment --><p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for the available options in each algorithm's <code>Builder</code>.</p>
<h1>Polymorphism</h1>
<p>All methods implement the <code>Builder</code>, <code>Prebuilt</code> and <code>Searcher</code> interfaces via inheritance. This means that users can swap algorithms at run-time:</p>
<div class="fragment"><div class="line">std::unique_ptr&lt;<a class="code hl_class" href="classknncolle_1_1Builder.html">knncolle::Builder</a>&lt;<span class="keyword">decltype</span>(mat), <span class="keywordtype">double</span>&gt; &gt; ptr;</div>
<div class="line"><span class="keywordflow">if</span> (algorithm == <span class="stringliteral">&quot;brute-force&quot;</span>) {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1BruteforceBuilder.html">knncolle::BruteforceBuilder&lt;&gt;</a>);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (algorithm == <span class="stringliteral">&quot;kmknn&quot;</span>) {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1KmknnBuilder.html">knncolle::KmknnBuilder&lt;&gt;</a>);</div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder&lt;&gt;</a>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> some_prebuilt = ptr-&gt;<a class="code hl_function" href="classknncolle_1_1Builder.html#afeda432debae999f988f32f147055251">build_unique</a>(mat);</div>
<div class="line"><span class="keyword">auto</span> some_results = <a class="code hl_function" href="namespaceknncolle.html#a22e035b2d5eb293fd828a67e61f3213d">knncolle::find_nearest_neighbors</a>(*some_prebuilt, 10); </div>
<div class="ttc" id="aclassknncolle_1_1BruteforceBuilder_html"><div class="ttname"><a href="classknncolle_1_1BruteforceBuilder.html">knncolle::BruteforceBuilder</a></div><div class="ttdoc">Perform a brute-force nearest neighbor search.</div><div class="ttdef"><b>Definition</b> Bruteforce.hpp:210</div></div>
<div class="ttc" id="aclassknncolle_1_1Builder_html"><div class="ttname"><a href="classknncolle_1_1Builder.html">knncolle::Builder</a></div><div class="ttdoc">Interface to build nearest-neighbor search indices.</div><div class="ttdef"><b>Definition</b> Builder.hpp:22</div></div>
</div><!-- fragment --><p>Each class is also heavily templated to enable compile-time polymorphism. We default to <code>int</code>s for the indices and <code>double</code>s for the distances. If precision is not a concern, one can often achieve greater speed by swapping all <code>double</code>s with <code>float</code>s. The choice of distance calculation is also a compile-time parameter for most subclasses, and users can define their own classes to use a custom distance.</p>
<p>The choice of input data is another compile-time paramter, as defined by the <code>MockMatrix</code> interface. Advanced users can define their own inputs to, e.g., read from file-backed or sparse matrices. For example, we implement the <code>L2NormalizedMatrix</code> class to apply on-the-fly L2 normalization of each observation's vector of coordinates. We then combine this with the <code>L2NormalizedBuilder</code> class to transform an existing neighbor search method from Euclidean to cosine distances.</p>
<div class="fragment"><div class="line"><span class="keywordtype">bool</span> use_cosine = <span class="keyword">true</span>;</div>
<div class="line">std::unique_ptr&lt;<a class="code hl_class" href="classknncolle_1_1Builder.html">knncolle::Builder</a>&lt;<span class="keyword">decltype</span>(mat), <span class="keywordtype">double</span>&gt; &gt; ptr;</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> (use_cosine) {</div>
<div class="line">    <span class="keyword">typedef</span> <a class="code hl_namespace" href="namespaceknncolle.html">knncolle</a>:VptreeBuilder&lt;</div>
<div class="line">        <a class="code hl_struct" href="structknncolle_1_1EuclideanDistance.html">knncolle::EuclideanDistance</a>,</div>
<div class="line">        <a class="code hl_class" href="classknncolle_1_1L2NormalizedMatrix.html">knncolle::L2NormalizedMatrix&lt;&gt;</a> <span class="comment">// only use as a template argument.</span></div>
<div class="line">    &gt; L2VptreeBuilder;</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1L2NormalizedBuilder.html">knncolle::L2NormalizedBuilder</a>(<span class="keyword">new</span> L2VptreeBuilder));</div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_namespace" href="namespaceknncolle.html">knncolle</a>:VptreeBuilder&lt;&gt;);</div>
<div class="line">}</div>
<div class="ttc" id="aclassknncolle_1_1L2NormalizedBuilder_html"><div class="ttname"><a href="classknncolle_1_1L2NormalizedBuilder.html">knncolle::L2NormalizedBuilder</a></div><div class="ttdoc">Wrapper around a builder with L2 normalization.</div><div class="ttdef"><b>Definition</b> L2Normalized.hpp:214</div></div>
<div class="ttc" id="aclassknncolle_1_1L2NormalizedMatrix_html"><div class="ttname"><a href="classknncolle_1_1L2NormalizedMatrix.html">knncolle::L2NormalizedMatrix</a></div><div class="ttdoc">Wrapper around a matrix with L2 normalization.</div><div class="ttdef"><b>Definition</b> L2Normalized.hpp:162</div></div>
<div class="ttc" id="anamespaceknncolle_html"><div class="ttname"><a href="namespaceknncolle.html">knncolle</a></div><div class="ttdoc">Collection of KNN algorithms.</div><div class="ttdef"><b>Definition</b> Bruteforce.hpp:21</div></div>
<div class="ttc" id="astructknncolle_1_1EuclideanDistance_html"><div class="ttname"><a href="structknncolle_1_1EuclideanDistance.html">knncolle::EuclideanDistance</a></div><div class="ttdoc">Compute Euclidean distances between two input vectors.</div><div class="ttdef"><b>Definition</b> distances.hpp:68</div></div>
</div><!-- fragment --><p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for more details on these interfaces.</p>
<h1>Building projects with <b>knncolle</b></h1>
<h2>CMake with <code>FetchContent</code></h2>
<p>If you're using CMake, you just need to add something like this to your <code>CMakeLists.txt</code>:</p>
<div class="fragment"><div class="line">include(FetchContent)</div>
<div class="line"> </div>
<div class="line">FetchContent_Declare(</div>
<div class="line">  knncolle</div>
<div class="line">  GIT_REPOSITORY https://github.com/knncolle/knncolle</div>
<div class="line">  GIT_TAG master # or any version of interest</div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line">FetchContent_MakeAvailable(knncolle)</div>
</div><!-- fragment --><p>Then you can link to <b>knncolle</b> to make the headers available during compilation:</p>
<div class="fragment"><div class="line"># For executables:</div>
<div class="line">target_link_libraries(myexe knncolle::knncolle)</div>
<div class="line"> </div>
<div class="line"># For libaries</div>
<div class="line">target_link_libraries(mylib INTERFACE knncolle::knncolle)</div>
</div><!-- fragment --><h2>CMake with <code>find_package()</code></h2>
<div class="fragment"><div class="line">find_package(knncolle_knncolle CONFIG REQUIRED)</div>
<div class="line">target_link_libraries(mylib INTERFACE knncolle::knncolle)</div>
</div><!-- fragment --><p>To install the library, use:</p>
<div class="fragment"><div class="line">mkdir build &amp;&amp; cd build</div>
<div class="line">cmake .. -DKNNCOLLE_TESTS=OFF</div>
<div class="line">cmake --build . --target install</div>
</div><!-- fragment --><p>By default, this will use <code>FetchContent</code> to fetch all external dependencies. If you want to install them manually, use <code>-DKNNCOLLE_FETCH_EXTERN=OFF</code>. See the commit hashes in <a href="extern/CMakeLists.txt"><code>extern/CMakeLists.txt</code></a> to find compatible versions of each dependency.</p>
<h2>Manual</h2>
<p>If you're not using CMake, the simple approach is to just copy the files in <code>include/</code> - either directly or with Git submodules - and include their path during compilation with, e.g., GCC's <code>-I</code>. This requires the external dependencies listed in <a href="extern/CMakeLists.txt"><code>extern/CMakeLists.txt</code></a>, which also need to be made available during compilation.</p>
<h1>References</h1>
<p>Wang X (2012). A fast exact k-nearest neighbors algorithm for high dimensional search using k-means clustering and triangle inequality. <em>Proc Int Jt Conf Neural Netw</em>, 43, 6:2351-2358.</p>
<p>Hanov S (2011). VP trees: A data structure for finding stuff fast. <a href="http://stevehanov.ca/blog/index.php?id=130">http://stevehanov.ca/blog/index.php?id=130</a></p>
<p>Yianilos PN (1993). Data structures and algorithms for nearest neighbor search in general metric spaces. <em>Proceedings of the Fourth Annual ACM-SIAM Symposium on Discrete Algorithms</em>, 311-321. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
