<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>knncolle: Collection of KNN algorithms</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">knncolle
   </div>
   <div id="projectbrief">Collection of KNN methods in C++</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Collection of KNN algorithms </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md__2github_2workspace_2README"></a> <img src="https://github.com/knncolle/knncolle/actions/workflows/run-tests.yaml/badge.svg" alt="Unit tests" style="pointer-events: none;" class="inline"/> <img src="https://github.com/knncolle/knncolle/actions/workflows/doxygenate.yaml/badge.svg" alt="Documentation" style="pointer-events: none;" class="inline"/> <a href="https://codecov.io/gh/knncolle/knncolle"><img src="https://codecov.io/gh/knncolle/knncolle/branch/master/graph/badge.svg" alt="Codecov" style="pointer-events: none;" class="inline"/></a></p>
<h1>Overview</h1>
<p><b>knncolle</b> is a header-only C++ library that collects a variety of different k-nearest neighbor algorithms under a consistent interface. The aim is to enable downstream libraries to easily switch between different methods with a single runtime flag, or by just swapping out the relevant constructors at compile time.</p>
<p>Currently, we support the following methods:</p>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/22247818/">K-means with k-nearest neighbors</a>, an exact search that uses k-means clustering to index points.</li>
<li><a href="http://stevehanov.ca/blog/?id=130">Vantage point tree</a>, an exact search that uses the tree of the same name.</li>
<li><a href="https://github.com/spotify/annoy/">Annoy</a>, an approximate search based on random projections.</li>
<li><a href="https://github.com/nmslib/hnswlib/">HNSW</a>, an approximate search based on hierarchical graphs.</li>
<li>Brute force search.</li>
</ul>
<p>Most of the code in this library is derived from the <a href="https://bioconductor.org/packages/release/bioc/html/BiocNeighbors.html"><b>BiocNeighbors</b> R package</a>.</p>
<h1>Quick start</h1>
<p>Given a matrix with dimensions in the rows and observations in the columns, we can do:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="knncolle_8hpp.html">knncolle/knncolle.hpp</a>&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Wrap our data in a light SimpleMatrix.</span></div>
<div class="line"><a class="code hl_class" href="classknncolle_1_1SimpleMatrix.html">knncolle::SimpleMatrix&lt;int, int, double&gt;</a> mat(ndim, nobs, matrix.data());</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Build a VP-tree index. </span></div>
<div class="line"><a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder&lt;&gt;</a> vp_builder;</div>
<div class="line"><span class="keyword">auto</span> vp_index = vp_builder.build(mat);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Find 10 nearest neighbors of every element.</span></div>
<div class="line"><span class="keyword">auto</span> results = knncolle::find_nearest_neighbors(*vp_index, 10); </div>
<div class="ttc" id="aclassknncolle_1_1SimpleMatrix_html"><div class="ttname"><a href="classknncolle_1_1SimpleMatrix.html">knncolle::SimpleMatrix</a></div><div class="ttdoc">Simple wrapper for an in-memory matrix.</div><div class="ttdef"><b>Definition</b> MockMatrix.hpp:116</div></div>
<div class="ttc" id="aclassknncolle_1_1VptreeBuilder_html"><div class="ttname"><a href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder</a></div><div class="ttdoc">Perform a nearest neighbor search based on a vantage point (VP) tree.</div><div class="ttdef"><b>Definition</b> Vptree.hpp:332</div></div>
<div class="ttc" id="aknncolle_8hpp_html"><div class="ttname"><a href="knncolle_8hpp.html">knncolle.hpp</a></div><div class="ttdoc">Umbrella header to include all algorithms.</div></div>
</div><!-- fragment --><p>The <code>find_nearest_neighbors()</code> call will return a vector of (index, distance) pairs, containing the requested number of neighbors in order of increasing distance from the query point. (In cases where the requested number of neighbors is greater than the actual number of neighbors, the latter is returned.)</p>
<p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for more details.</p>
<h1>Searching in more detail</h1>
<p>We can perform the search manually by constructing a <code>Searcher</code> instance and looping over the elements of interest. Continuing with the same variables defined in the previous section, we could replace the <code>find_nearest_neighbors()</code> call with:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> searcher = vp_index-&gt;initialize();</div>
<div class="line">std::vector&lt;std::pair&lt;int, double&gt; &gt; results;</div>
<div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> o = 0; o &lt; nobs; ++o) {</div>
<div class="line">    searcher-&gt;search(o, 10, results);</div>
<div class="line">    <span class="comment">// Do something with the search &#39;results&#39; for &#39;o&#39;.</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>Similarly, we can query the prebuilt index for the neighbors of an arbitrary vector. The code below searches for the nearest 5 neighbors to a query vector at the origin:</p>
<div class="fragment"><div class="line">std::vector&lt;double&gt; query(ndim);</div>
<div class="line">searcher-&gt;search(query.data(), 5, results);</div>
</div><!-- fragment --><p>To parallelize the loop, we just need to construct a separate <code>Searcher</code> (and the result vector) for each thread. This is already implemented in <code>find_nearest_neighbors()</code> but is also easy to do by hand, e.g., with OpenMP:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#pragma omp parallel num_threads(5)</span></div>
<div class="line">{</div>
<div class="line">    <span class="keyword">auto</span> searcher = vp_index-&gt;initialize();</div>
<div class="line">    std::vector&lt;std::pair&lt;int, double&gt; &gt; results;</div>
<div class="line"><span class="preprocessor">    #pragma omp for</span></div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> o = 0; o &lt; nobs; ++o) {</div>
<div class="line">        searcher-&gt;search(o, 10, results);</div>
<div class="line">        <span class="comment">// Do something with the search &#39;results&#39; for &#39;o&#39;.</span></div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><h1>Tuning index construction</h1>
<p>Some algorithms allow the user to modify the parameters of the search by passing options in the relevant <code>Builder</code> constructor. For example, the KMKNN method has several options for the k-means clustering step. We could, say, specify which initialization algorithm to use:</p>
<div class="fragment"><div class="line"><a class="code hl_struct" href="structknncolle_1_1KmknnOptions.html">knncolle::KmknnOptions&lt;&gt;</a> kk_opt;</div>
<div class="line">kk_opt.<a class="code hl_variable" href="structknncolle_1_1KmknnOptions.html#a01ab1d6e283fa8945723f33942e310c0">initialize_algorithm</a>.reset(</div>
<div class="line">    <span class="keyword">new</span> kmeans::InitializeRandom&lt;kmeans::SimpleMatrix&lt;double, int, int&gt;, <span class="keywordtype">int</span>, <span class="keywordtype">double</span>&gt;</div>
<div class="line">);</div>
<div class="ttc" id="astructknncolle_1_1KmknnOptions_html"><div class="ttname"><a href="structknncolle_1_1KmknnOptions.html">knncolle::KmknnOptions</a></div><div class="ttdoc">Options for KmknnBuilder and KmknnPrebuilt construction.</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:35</div></div>
<div class="ttc" id="astructknncolle_1_1KmknnOptions_html_a01ab1d6e283fa8945723f33942e310c0"><div class="ttname"><a href="structknncolle_1_1KmknnOptions.html#a01ab1d6e283fa8945723f33942e310c0">knncolle::KmknnOptions::initialize_algorithm</a></div><div class="ttdeci">std::shared_ptr&lt; kmeans::Initialize&lt; kmeans::SimpleMatrix&lt; Store_, Index_, Dim_ &gt;, Index_, Store_ &gt; &gt; initialize_algorithm</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:49</div></div>
</div><!-- fragment --><p>Or modify the behavior of the refinement algorithm:</p>
<div class="fragment"><div class="line">kmeans::RefineLloydOptions ll_opt;</div>
<div class="line">ll_opt.max_iterations = 20;</div>
<div class="line">ll_opt.num_threads = 5;</div>
<div class="line">kk_opt.<a class="code hl_variable" href="structknncolle_1_1KmknnOptions.html#adf03e5a3046a1da5cacff93d37975ff8">refine_algorithm</a>.reset(</div>
<div class="line">    <span class="keyword">new</span> kmeans::RefineLloyd&lt;kmeans::SimpleMatrix&lt;double, int, int&gt;, <span class="keywordtype">int</span>, <span class="keywordtype">double</span>&gt;(ll_opt)</div>
<div class="line">);</div>
<div class="ttc" id="astructknncolle_1_1KmknnOptions_html_adf03e5a3046a1da5cacff93d37975ff8"><div class="ttname"><a href="structknncolle_1_1KmknnOptions.html#adf03e5a3046a1da5cacff93d37975ff8">knncolle::KmknnOptions::refine_algorithm</a></div><div class="ttdeci">std::shared_ptr&lt; kmeans::Refine&lt; kmeans::SimpleMatrix&lt; Store_, Index_, Dim_ &gt;, Index_, Store_ &gt; &gt; refine_algorithm</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:55</div></div>
</div><!-- fragment --><p>After which, we construct our <code>KmknnBuilder</code>, build our <code>KmknnPrebuilt</code> index, and proceed with the nearest-neighbor search.</p>
<div class="fragment"><div class="line"><a class="code hl_class" href="classknncolle_1_1KmknnBuilder.html">knncolle::KmknnBuilder&lt;&gt;</a> kk_builder(kk_opt);</div>
<div class="line"><span class="keyword">auto</span> kk_prebuilt = kk_builder.build(mat);</div>
<div class="line"><span class="keyword">auto</span> kk_results = knncolle::find_nearest_neighbors(*kk_prebuilt, 10); </div>
<div class="ttc" id="aclassknncolle_1_1KmknnBuilder_html"><div class="ttname"><a href="classknncolle_1_1KmknnBuilder.html">knncolle::KmknnBuilder</a></div><div class="ttdoc">Perform a nearest neighbor search based on k-means clustering.</div><div class="ttdef"><b>Definition</b> Kmknn.hpp:395</div></div>
</div><!-- fragment --><p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for the available options in each algorithm's <code>Builder</code>.</p>
<h1>Polymorphism</h1>
<p>All methods implement the <code>Builder</code>, <code>Prebuilt</code> and <code>Searcher</code> interfaces via inheritance. This means that users can swap algorithms at run-time:</p>
<div class="fragment"><div class="line">std::unique_ptr&lt;knncolle::Builder&lt;&gt; &gt; ptr;</div>
<div class="line"><span class="keywordflow">if</span> (algorithm == <span class="stringliteral">&quot;brute-force&quot;</span>) {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1BruteforceBuilder.html">knncolle::BruteforceBuilder&lt;&gt;</a>);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (algorithm == <span class="stringliteral">&quot;kmknn&quot;</span>) {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1KmknnBuilder.html">knncolle::KmknnBuilder&lt;&gt;</a>);</div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder&lt;&gt;</a>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> some_prebuilt = ptr-&gt;build(mat);</div>
<div class="line"><span class="keyword">auto</span> some_results = <a class="code hl_function" href="find__nearest__neighbors_8hpp.html#a22e035b2d5eb293fd828a67e61f3213d">knncolle::find_nearest_neighbors</a>(*some_prebuilt, 10); </div>
<div class="ttc" id="aclassknncolle_1_1BruteforceBuilder_html"><div class="ttname"><a href="classknncolle_1_1BruteforceBuilder.html">knncolle::BruteforceBuilder</a></div><div class="ttdoc">Perform a brute-force nearest neighbor search.</div><div class="ttdef"><b>Definition</b> Bruteforce.hpp:151</div></div>
<div class="ttc" id="afind__nearest__neighbors_8hpp_html_a22e035b2d5eb293fd828a67e61f3213d"><div class="ttname"><a href="find__nearest__neighbors_8hpp.html#a22e035b2d5eb293fd828a67e61f3213d">knncolle::find_nearest_neighbors</a></div><div class="ttdeci">NeighborList&lt; Index_, Float_ &gt; find_nearest_neighbors(const Prebuilt&lt; Dim_, Index_, Float_ &gt; &amp;index, int k, int num_threads=1)</div><div class="ttdef"><b>Definition</b> find_nearest_neighbors.hpp:49</div></div>
</div><!-- fragment --><p>Each class is also heavily templated to enable compile-time polymorphism:</p>
<ul>
<li>We default to <code>int</code>s for the indices and <code>double</code>s for the distances. If precision is not a concern, one can often achieve greater speed by swapping all <code>double</code>s with <code>float</code>s.</li>
<li>The choice of distance calculation is often a compile-time parameter, as defined by the <code>MockDistance</code> compile-time interface. Advanced users can define their own classes to customize the distance calculations.</li>
<li>The choice of input data is another compile-time paramter, as defined by the <code>MockMatrix</code> interface. Advanced users can define their own inputs to, e.g., read from file-backed or sparse matrices.</li>
</ul>
<p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for more details on these interfaces.</p>
<h1>Building projects with <b>knncolle</b></h1>
<h2>CMake with <code>FetchContent</code></h2>
<p>If you're using CMake, you just need to add something like this to your <code>CMakeLists.txt</code>:</p>
<div class="fragment"><div class="line">include(FetchContent)</div>
<div class="line"> </div>
<div class="line">FetchContent_Declare(</div>
<div class="line">  knncolle</div>
<div class="line">  GIT_REPOSITORY https://github.com/knncolle/knncolle</div>
<div class="line">  GIT_TAG master # or any version of interest</div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line">FetchContent_MakeAvailable(knncolle)</div>
</div><!-- fragment --><p>Then you can link to <b>knncolle</b> to make the headers available during compilation:</p>
<div class="fragment"><div class="line"># For executables:</div>
<div class="line">target_link_libraries(myexe knncolle::knncolle)</div>
<div class="line"> </div>
<div class="line"># For libaries</div>
<div class="line">target_link_libraries(mylib INTERFACE knncolle::knncolle)</div>
</div><!-- fragment --><h2>CMake with <code>find_package()</code></h2>
<div class="fragment"><div class="line">find_package(knncolle_knncolle CONFIG REQUIRED)</div>
<div class="line">target_link_libraries(mylib INTERFACE knncolle::knncolle)</div>
</div><!-- fragment --><p>To install the library, use:</p>
<div class="fragment"><div class="line">mkdir build &amp;&amp; cd build</div>
<div class="line">cmake .. -DKNNCOLLE_TESTS=OFF</div>
<div class="line">cmake --build . --target install</div>
</div><!-- fragment --><p>By default, this will use <code>FetchContent</code> to fetch all external dependencies. If you want to install them manually, use <code>-DKNNCOLLE_FETCH_EXTERN=OFF</code>. See the commit hashes in <a href="extern/CMakeLists.txt"><code>extern/CMakeLists.txt</code></a> to find compatible versions of each dependency.</p>
<h2>Manual</h2>
<p>If you're not using CMake, the simple approach is to just copy the files in <code>include/</code> - either directly or with Git submodules - and include their path during compilation with, e.g., GCC's <code>-I</code>. This requires the external dependencies listed in <a href="extern/CMakeLists.txt"><code>extern/CMakeLists.txt</code></a>, which also need to be made available during compilation.</p>
<h1>References</h1>
<p>Wang X (2012). A fast exact k-nearest neighbors algorithm for high dimensional search using k-means clustering and triangle inequality. <em>Proc Int Jt Conf Neural Netw</em>, 43, 6:2351-2358.</p>
<p>Hanov S (2011). VP trees: A data structure for finding stuff fast. <a href="http://stevehanov.ca/blog/index.php?id=130">http://stevehanov.ca/blog/index.php?id=130</a></p>
<p>Yianilos PN (1993). Data structures and algorithms for nearest neighbor search in general metric spaces. <em>Proceedings of the Fourth Annual ACM-SIAM Symposium on Discrete Algorithms</em>, 311-321.</p>
<p>Bernhardsson E (2018). Annoy. <a href="https://github.com/spotify/annoy">https://github.com/spotify/annoy</a></p>
<p>Malkov YA, Yashunin DA (2016). Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs. <em>arXiv</em>, <a href="https://arxiv.org/abs/1603.09320">https://arxiv.org/abs/1603.09320</a> </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
