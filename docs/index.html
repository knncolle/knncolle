<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>knncolle: Collection of KNN algorithms</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">knncolle
   </div>
   <div id="projectbrief">Collection of KNN methods in C++</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="doc-content">
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Collection of KNN algorithms </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md__2github_2workspace_2README"></a></p>
<p><img src="https://github.com/knncolle/knncolle/actions/workflows/run-tests.yaml/badge.svg" alt="Unit tests" style="pointer-events: none;" class="inline"/> <img src="https://github.com/knncolle/knncolle/actions/workflows/doxygenate.yaml/badge.svg" alt="Documentation" style="pointer-events: none;" class="inline"/> <a href="https://codecov.io/gh/knncolle/knncolle"><img src="https://codecov.io/gh/knncolle/knncolle/branch/master/graph/badge.svg" alt="Codecov" style="pointer-events: none;" class="inline"/></a></p>
<h1>Overview</h1>
<p><b>knncolle</b> is a header-only C++ library that collects a variety of different k-nearest neighbor algorithms under a consistent interface. The aim is to enable downstream libraries to easily switch between different methods with a single runtime flag, or by just swapping out the relevant constructors at compile time.</p>
<p>The core library implements various interfaces along with the following methods:</p>
<ul>
<li><a href="http://stevehanov.ca/blog/?id=130">Vantage point tree</a>, an exact search that uses the tree of the same name.</li>
<li>Brute force search, mostly implemented for testing.</li>
</ul>
<p>Additional libraries extend the <b>knncolle</b> framework to more algorithms:</p>
<ul>
<li><a href="https://github.com/knncolle/knncolle_kmknn"><b>knncolle_kmknn</b></a> wraps <a href="https://pubmed.ncbi.nlm.nih.gov/22247818/">KMKNN</a>, an exact search based on k-means clustering.</li>
<li><a href="https://github.com/knncolle/knncolle_annoy"><b>knncolle_annoy</b></a> wraps <a href="https://github.com/spotify/annoy/">Annoy</a>, an approximate search based on random projections.</li>
<li><a href="https://github.com/knncolle/knncolle_hnsw"><b>knncolle_hnsw</b></a> wraps <a href="https://github.com/nmslib/hnswlib/">HNSW</a>, an approximate search based on hierarchical graphs.</li>
</ul>
<p>Most of the code in this library is derived from the <a href="https://bioconductor.org/packages/release/bioc/html/BiocNeighbors.html"><b>BiocNeighbors</b> R package</a>.</p>
<h1>Quick start</h1>
<p>Given a matrix with dimensions in the rows and observations in the columns, we can do:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="knncolle_8hpp.html">knncolle/knncolle.hpp</a>&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> ndim = 10;</div>
<div class="line"><span class="keywordtype">int</span> nobs = 1000;</div>
<div class="line">std::vector&lt;double&gt; matrix(ndim * nobs); <span class="comment">// column-major dims x obs matrix. </span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Wrap our data in a SimpleMatrix.</span></div>
<div class="line"><a class="code hl_class" href="classknncolle_1_1SimpleMatrix.html">knncolle::SimpleMatrix</a>&lt;</div>
<div class="line">    <span class="comment">/* observation index */</span> int,</div>
<div class="line">    <span class="comment">/* data type */</span> <span class="keywordtype">double</span></div>
<div class="line">&gt; mat(ndim, nobs, matrix.data());</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Build a VP-tree index with double-precision Euclidean distances.</span></div>
<div class="line"><span class="keyword">auto</span> edist = std::make_shared&lt;<a class="code hl_class" href="classknncolle_1_1EuclideanDistance.html">knncolle::EuclideanDistance</a>&lt;</div>
<div class="line">    <span class="comment">/* data type = */</span> double,</div>
<div class="line">    <span class="comment">/* distance type = */</span> <span class="keywordtype">double</span></div>
<div class="line">&gt; &gt;();</div>
<div class="line"><a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder</a>&lt;</div>
<div class="line">    <span class="comment">/* observation index */</span> int, </div>
<div class="line">    <span class="comment">/* data type */</span> double, </div>
<div class="line">    <span class="comment">/* distance type */</span> <span class="keywordtype">double</span></div>
<div class="line">&gt; vp_builder(std::move(edist));</div>
<div class="line"><span class="keyword">auto</span> vp_index = vp_builder.build_unique(mat);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Find 10 nearest neighbors of every observation.</span></div>
<div class="line"><span class="keyword">auto</span> results = <a class="code hl_function" href="namespaceknncolle.html#a2c6d8b116464bab254bda34216338c3c">knncolle::find_nearest_neighbors</a>(*vp_index, 10); </div>
<div class="line"> </div>
<div class="line">results[0].first; <span class="comment">// indices of neighbors of the first observation</span></div>
<div class="line">results[0].second; <span class="comment">// distances to neighbors of the first observation</span></div>
<div class="ttc" id="aclassknncolle_1_1EuclideanDistance_html"><div class="ttname"><a href="classknncolle_1_1EuclideanDistance.html">knncolle::EuclideanDistance</a></div><div class="ttdoc">Compute Euclidean distances between two input vectors.</div><div class="ttdef"><b>Definition</b> distances.hpp:103</div></div>
<div class="ttc" id="aclassknncolle_1_1SimpleMatrix_html"><div class="ttname"><a href="classknncolle_1_1SimpleMatrix.html">knncolle::SimpleMatrix</a></div><div class="ttdoc">Simple wrapper for an in-memory matrix.</div><div class="ttdef"><b>Definition</b> Matrix.hpp:133</div></div>
<div class="ttc" id="aclassknncolle_1_1VptreeBuilder_html"><div class="ttname"><a href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder</a></div><div class="ttdoc">Perform a nearest neighbor search based on a vantage point (VP) tree.</div><div class="ttdef"><b>Definition</b> Vptree.hpp:436</div></div>
<div class="ttc" id="aknncolle_8hpp_html"><div class="ttname"><a href="knncolle_8hpp.html">knncolle.hpp</a></div><div class="ttdoc">Umbrella header for all algorithms.</div></div>
<div class="ttc" id="anamespaceknncolle_html_a2c6d8b116464bab254bda34216338c3c"><div class="ttname"><a href="namespaceknncolle.html#a2c6d8b116464bab254bda34216338c3c">knncolle::find_nearest_neighbors</a></div><div class="ttdeci">NeighborList&lt; Index_, Distance_ &gt; find_nearest_neighbors(const Prebuilt&lt; Index_, Data_, Distance_ &gt; &amp;index, int k, int num_threads=1)</div><div class="ttdef"><b>Definition</b> find_nearest_neighbors.hpp:129</div></div>
</div><!-- fragment --><p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for more details.</p>
<h1>Searching in more detail</h1>
<p>We can perform the search manually by constructing a <code>Searcher</code> instance and looping over the elements of interest. Continuing with the same variables defined in the previous section, we could replace the <code>find_nearest_neighbors()</code> call with:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> searcher = vp_index-&gt;initialize();</div>
<div class="line">std::vector&lt;int&gt; indices;</div>
<div class="line">std::vector&lt;double&gt; distances;</div>
<div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> o = 0; o &lt; nobs; ++o) {</div>
<div class="line">    searcher-&gt;search(o, 10, &amp;indices, &amp;distances);</div>
<div class="line">    <span class="comment">// Do something with the search results for &#39;o&#39;.</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>Similarly, we can query the prebuilt index for the neighbors of an arbitrary vector. The code below searches for the nearest 5 neighbors to a query vector at the origin:</p>
<div class="fragment"><div class="line">std::vector&lt;double&gt; query(ndim);</div>
<div class="line">searcher-&gt;search(query.data(), 5, &amp;indices, &amp;distances);</div>
</div><!-- fragment --><p>To parallelize the loop, we just need to construct a separate <code>Searcher</code> (and the result vector) for each thread. This is already implemented in <code>find_nearest_neighbors()</code> but is also easy to do by hand, e.g., with OpenMP:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#pragma omp parallel num_threads(5)</span></div>
<div class="line">{</div>
<div class="line">    <span class="keyword">auto</span> searcher = vp_index-&gt;initialize();</div>
<div class="line">    std::vector&lt;int&gt; indices;</div>
<div class="line">    std::vector&lt;double&gt; distances;</div>
<div class="line"><span class="preprocessor">    #pragma omp for</span></div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> o = 0; o &lt; nobs; ++o) {</div>
<div class="line">        searcher-&gt;search(o, 10, &amp;indices, &amp;distances);</div>
<div class="line">        <span class="comment">// Do something with the search &#39;results&#39; for &#39;o&#39;.</span></div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>Either (or both) of <code>indices</code> and <code>distances</code> may be <code>NULL</code>, in which case the corresponding values are not reported. This allows implementations to skip the extraction of distances when only the identities of the neighbors are of interest.</p>
<div class="fragment"><div class="line">searcher-&gt;search(0, 5, &amp;indices, NULL);</div>
</div><!-- fragment --><h1>Finding all neighbors within range</h1>
<p>A related problem involves finding all neighbors within a certain distance of an observation. This can be achieved using the <code>Searcher::search_all()</code> method:</p>
<div class="fragment"><div class="line"><span class="keywordflow">if</span> (seacher-&gt;can_search_all()) {</div>
<div class="line">    <span class="comment">// Report all neighbors within a distance of 10 from the first point.</span></div>
<div class="line">    searcher-&gt;search_all(0, 10, &amp;indices, &amp;distances);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Report all neighbors within a distance of 0.5 from a query point.</span></div>
<div class="line">    searcher-&gt;search_all(query.data(), 0.5, &amp;indices, &amp;distances);</div>
<div class="line">}</div>
</div><!-- fragment --><p>This method is optional so developers of <code>Searcher</code> subclasses may choose to not implement it. Applications should check <code>Searcher::can_search_all()</code> before attempting a call, as shown above. Otherwise, the default method will raise an exception.</p>
<h1>Polymoprhism via interfaces</h1>
<p>All KNN search algorithms implement the <code>Builder</code>, <code>Prebuilt</code> and <code>Searcher</code> interfaces via inheritance. This means that users can swap algorithms at run-time:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> dist_type = std::make_shared&lt;knncolle::EuclideanDistance&lt;double, double&gt; &gt;();</div>
<div class="line"> </div>
<div class="line">std::unique_ptr&lt;knncolle::Builder&lt;int, double, double&gt; &gt; ptr;</div>
<div class="line"><span class="keywordflow">if</span> (algorithm == <span class="stringliteral">&quot;brute-force&quot;</span>) {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1BruteforceBuilder.html">knncolle::BruteforceBuilder&lt;int, double, double&gt;</a>(dist_type));</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (algorithm == <span class="stringliteral">&quot;vp-tree&quot;</span>) {</div>
<div class="line">    ptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder&lt;int, double, double&gt;</a>(dist_type));</div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">    <span class="comment">// do something else</span></div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> some_prebuilt = ptr-&gt;build_unique(mat);</div>
<div class="line"><span class="keyword">auto</span> some_results = <a class="code hl_function" href="namespaceknncolle.html#a2c6d8b116464bab254bda34216338c3c">knncolle::find_nearest_neighbors</a>(*some_prebuilt, 10); </div>
<div class="ttc" id="aclassknncolle_1_1BruteforceBuilder_html"><div class="ttname"><a href="classknncolle_1_1BruteforceBuilder.html">knncolle::BruteforceBuilder</a></div><div class="ttdoc">Perform a brute-force nearest neighbor search.</div><div class="ttdef"><b>Definition</b> Bruteforce.hpp:229</div></div>
</div><!-- fragment --><p>Similarly, for algorithms that accept a <code>DistanceMetric</code>, we can switch between distances at run-time:</p>
<div class="fragment"><div class="line">std::shared_ptr&lt;knncolle::DistanceMetric&lt;double, double&gt; &gt; distptr;</div>
<div class="line"><span class="keywordflow">if</span> (distance == <span class="stringliteral">&quot;euclidean&quot;</span>) {</div>
<div class="line">    distptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1EuclideanDistance.html">knncolle::EuclideanDistance&lt;double, double&gt;</a>);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (distance == <span class="stringliteral">&quot;manhattan&quot;</span>) {</div>
<div class="line">    distptr.reset(<span class="keyword">new</span> <a class="code hl_class" href="classknncolle_1_1ManhattanDistance.html">knncolle::ManhattanDistance&lt;double, double&gt;</a>);</div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">    <span class="comment">// do something else.</span></div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder&lt;int, double, double&gt;</a> vp_builder(std::move(distptr));</div>
<div class="ttc" id="aclassknncolle_1_1ManhattanDistance_html"><div class="ttname"><a href="classknncolle_1_1ManhattanDistance.html">knncolle::ManhattanDistance</a></div><div class="ttdoc">Compute Manhattan distances between two input vectors.</div><div class="ttdef"><b>Definition</b> distances.hpp:143</div></div>
</div><!-- fragment --><p>We can even switch between input matrix representations at run-time, as long as they follow the <code>Matrix</code> interface. This allows the various <code>Builder</code> classes to accept input data in other formats (e.g., sparse, file-backed). For example, <b>knncolle</b> implements the <code>L2NormalizedMatrix</code> subclass to apply on-the-fly L2 normalization of each observation's vector of coordinates. This is used inside the <code>L2NormalizedBuilder</code> class to transform an existing neighbor search method from Euclidean to cosine distances.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> builder = std::make_shared&lt;knncolle::VptreeBuilder&lt;int, double, double&gt; &gt;(</div>
<div class="line">    std::make_shared&lt;knncolle::EuclideanDistance&lt;double, double&gt; &gt;()</div>
<div class="line">);</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> l2builder = std::make_shared&lt;<a class="code hl_class" href="classknncolle_1_1L2NormalizedBuilder.html">knncolle::L2NormalizedBuilder</a>&lt;</div>
<div class="line">    <span class="comment">/* observation index */</span> int,</div>
<div class="line">    <span class="comment">/* data type */</span> double,</div>
<div class="line">    <span class="comment">/* distance type */</span> double,</div>
<div class="line">    <span class="comment">/* normalized type */</span> <span class="keywordtype">double</span></div>
<div class="line">&gt; &gt;(std::move(builder));</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Any Matrix &#39;mat&#39; is automatically wrapped in a L2NormalizedMatrix</span></div>
<div class="line"><span class="comment">// before being passed to &#39;builder-&gt;build_unique&#39;.</span></div>
<div class="line"><span class="keyword">auto</span> l2index = l2builder-&gt;build_unique(mat);</div>
<div class="ttc" id="aclassknncolle_1_1L2NormalizedBuilder_html"><div class="ttname"><a href="classknncolle_1_1L2NormalizedBuilder.html">knncolle::L2NormalizedBuilder</a></div><div class="ttdoc">Wrapper around a builder with L2 normalization.</div><div class="ttdef"><b>Definition</b> L2Normalized.hpp:211</div></div>
</div><!-- fragment --><p>Check out the <a href="https://knncolle.github.io/knncolle/">reference documentation</a> for more details on these interfaces.</p>
<h1>Modifying template parameters</h1>
<p>Each interface has a few template parameters to define its types. In general, we recommend using <code>int</code>s for the observation indices and <code>double</code>s for the data and distances. If precision is not a concern, we can achieve greater speed by swapping <code>double</code>s with <code>float</code>s. We may also need to swap <code>int</code> with <code>size_t</code> for larger datasets, e.g., more than 2 billion observations.</p>
<p>Advanced users can set up the templates to bypass virtual dispatch at the cost of more compile-time complexity. For example, we could parametrize the <code>VptreeBuilder</code> so that it is hard-coded to use Euclidean distances and to only accept column-major in-memory matrices. This gives the compiler an opportunity to devirtualize the relevant method calls for a potential performance improvement.</p>
<div class="fragment"><div class="line"><span class="keyword">typedef</span> <a class="code hl_class" href="classknncolle_1_1VptreeBuilder.html">knncolle::VptreeBuilder</a>&lt;</div>
<div class="line">    int,</div>
<div class="line">    double,</div>
<div class="line">    double,</div>
<div class="line">    kncolle::SimpleMatrix&lt;int, double&gt;,</div>
<div class="line">    <a class="code hl_class" href="classknncolle_1_1EuclideanDistance.html">knncolle::EuclideanDistance&lt;double, double&gt;</a></div>
<div class="line">&gt; VptreeEuclideanSimple;</div>
</div><!-- fragment --><h1>Building projects with <b>knncolle</b></h1>
<h2>CMake with <code>FetchContent</code></h2>
<p>If you're using CMake, you just need to add something like this to your <code>CMakeLists.txt</code>:</p>
<div class="fragment"><div class="line">include(FetchContent)</div>
<div class="line"> </div>
<div class="line">FetchContent_Declare(</div>
<div class="line">  knncolle</div>
<div class="line">  GIT_REPOSITORY https://github.com/knncolle/knncolle</div>
<div class="line">  GIT_TAG master # replace with a pinned release</div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line">FetchContent_MakeAvailable(knncolle)</div>
</div><!-- fragment --><p>Then you can link to <b>knncolle</b> to make the headers available during compilation:</p>
<div class="fragment"><div class="line"># For executables:</div>
<div class="line">target_link_libraries(myexe knncolle::knncolle)</div>
<div class="line"> </div>
<div class="line"># For libaries</div>
<div class="line">target_link_libraries(mylib INTERFACE knncolle::knncolle)</div>
</div><!-- fragment --><p>By default, this will use <code>FetchContent</code> to fetch all external dependencies. Applications are advised to pin the versions of each dependency for stability - see <a href="extern/CMakeLists.txt"><code>extern/CMakeLists.txt</code></a> to find suggested versions. If you want to install dependencies manually, set <code>-DKNNCOLLE_FETCH_EXTERN=OFF</code> in the Cmake configuration.</p>
<h2>CMake with <code>find_package()</code></h2>
<p>If <b>knncolle</b> is already installed on the system, it can be discovered via:</p>
<div class="fragment"><div class="line">find_package(knncolle_knncolle CONFIG REQUIRED)</div>
<div class="line">target_link_libraries(mylib INTERFACE knncolle::knncolle)</div>
</div><!-- fragment --><p>To install the library, use:</p>
<div class="fragment"><div class="line">mkdir build &amp;&amp; cd build</div>
<div class="line">cmake .. -DKNNCOLLE_TESTS=OFF</div>
<div class="line">cmake --build . --target install</div>
</div><!-- fragment --><p>Again, this will automatically acquire all its dependencies, see recommendations above.</p>
<h2>Manual</h2>
<p>If you're not using CMake, the simple approach is to just copy the files in <code>include/</code> - either directly or with Git submodules - and include their path during compilation with, e.g., GCC's <code>-I</code>. This will also require the external dependencies listed in <a href="extern/CMakeLists.txt"><code>extern/CMakeLists.txt</code></a>.</p>
<h1>References</h1>
<p>Hanov S (2011). VP trees: A data structure for finding stuff fast. <a href="http://stevehanov.ca/blog/index.php?id=130">http://stevehanov.ca/blog/index.php?id=130</a></p>
<p>Yianilos PN (1993). Data structures and algorithms for nearest neighbor search in general metric spaces. <em>Proceedings of the Fourth Annual ACM-SIAM Symposium on Discrete Algorithms</em>, 311-321. </p>
</div></div><!-- PageDoc -->
<a href="doxygen_crawl.html"></a>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
